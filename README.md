# Trabalho de Conclus√£o do Curso  - UFRGS 

Este espa√ßo est√£o os c√≥digos, notebooks e demais artefatos utilizados no Trabalho de Conclus√£o para o curso de Especializa√ß√£o em Engenheria de Software para Aplica√ß√µes de Ci√™ncia de Dados, UFRGS, 2024-2026.

Aluno: Luiz Ant√¥nio Marques Garcia
Orientador: Joel Lu√≠s Carbonera

## üìÅ Estrutura do Projeto

```bash
‚îú‚îÄ‚îÄ README.md                  # documenta√ß√£o do projeto
‚îú‚îÄ‚îÄ requirements.txt           # bibliotecas utilizadas no projeto
‚îú‚îÄ‚îÄ run_exp.py                 # executa um experimento 
‚îú‚îÄ‚îÄ params.yaml                # par√¢metros para gera√ß√£o arquivos individuais de experimentos
‚îú‚îÄ‚îÄ gera_configs.py            # cria v√°rios arquivos de par√¢metros em \configs a partir da leitura de params.yaml
‚îú‚îÄ‚îÄ run_all.py                 # executa os experimentos configurados nos .yaml em \configs
‚îú‚îÄ‚îÄ lote_run_all.bat           # executa v√°rios run_all.py
‚îú‚îÄ‚îÄ configs                    # pasta com arquivos de par√¢metros de cada experimento (.yaml)
‚îú‚îÄ‚îÄ datasets
‚îÇ   ‚îú‚îÄ‚îÄ adult_sklearn          # pasta com dataset principal, Adult Income do ScitLearn.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ adult_sklearn.csv         # dataset principal sem split
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ adult_sklearn_test.csv    # dataset split teste  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ adult_sklearn_train.csv   # dataset split treintamento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ adult_sklearn_val.csv     # dataset split valida√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ adult_uci         # datasets Adult Income da fonte UCI (n√£o foi utilizado nas an√°lises)
‚îÇ   ‚îú‚îÄ‚îÄ german_sklearn    # datasets com German Score do Scikit Learn (n√£o foi utilizado nas an√°lises)
‚îú‚îÄ‚îÄ src
    ‚îú‚îÄ‚îÄ datasets                        # c√≥digo de download dos datasets
    ‚îÇ   ‚îú‚îÄ‚îÄ download_adult_sklearn.py   # download e split do Adult Income do Scikit-learn
    ‚îÇ   ‚îî‚îÄ‚îÄ download_adult_uci.py       # download do Adult Income do UCI
    ‚îÇ   ‚îî‚îÄ‚îÄ download_german_sklearn.py  # download do German Score
	‚îú‚îÄ‚îÄ models                          # modelos utilziados
    ‚îÇ   ‚îî‚îÄ‚îÄ bernoulli_nb.py
	‚îÇ   ‚îî‚îÄ‚îÄ decision_tree.py
	‚îÇ   ‚îî‚îÄ‚îÄ logistic_regression.py
	‚îÇ   ‚îî‚îÄ‚îÄ neural_network.py
	‚îÇ   ‚îî‚îÄ‚îÄ random_forest.py
	‚îÇ   ‚îî‚îÄ‚îÄ svm.py
	‚îÇ   ‚îî‚îÄ‚îÄ xgboost.py
	‚îú‚îÄ‚îÄ mitigation
        ‚îú‚îÄ‚îÄ pre                                # mitigadores pr√©-processamento
			‚îî‚îÄ‚îÄ disparate_impact_remover.py
			‚îî‚îÄ‚îÄ reweighing.py
        ‚îú‚îÄ‚îÄ in                                 # mitigadores in-processing
        ‚îú‚îÄ‚îÄ post	                           # mitigadores p√≥s-processamento
			‚îî‚îÄ‚îÄ equalized_odds_postprocessing.py
			‚îî‚îÄ‚îÄ reject_option_classification.py
	‚îú‚îÄ‚îÄ metrics
    ‚îÇ   ‚îî‚îÄ‚îÄ evaluate_fairness.py        # m√©tricas de fairness dos experimentos
    ‚îÇ   ‚îî‚îÄ‚îÄ evaluate_performance.py     # m√©tricas de desempenho preditivo dos experimientos
    ‚îî‚îÄ‚îÄ results                         # pasta com codigos auxiliares
 	‚îÇ   ‚îî‚îÄ‚îÄ evaluate_fairness.py
 	‚îÇ   ‚îî‚îÄ‚îÄ results_mean_std.py         # retorna CSV agregado por m√©dio e devio padr√£o
‚îú‚îÄ‚îÄ TCC_experimentos                    # pasta com sa√≠das (runs) dos experimentos utilizados no TCC
	‚îú‚îÄ‚îÄ dfs_10x                         # log dos datasets entra e sa√≠da dos mitigadores para confer√™ncias
	‚îî‚îÄ‚îÄ runs_adult_10x_1.csv            # Sa√≠da do lote de 10 execu√ß√µes dos experimentos com par√¢metros em \configs
	‚îî‚îÄ‚îÄ runs_adult_10x_1_mean_std.csv   # O runs_adult_10x_1.csv agregado por m√©dia e desvio padr√£o (resultado de (results_mean_std.py))
‚îú‚îÄ‚îÄ TCC_imagens                         # Imagens utilizadas em Latex
‚îú‚îÄ‚îÄ TCC_notebooks                       # Noteboks Jupyter (Google Colab) para cria√ß√£o dos gr√°ficos do TCC
```

## Arquivo de par√¢metro do experimento

 Para execu√ß√£o de um experimento _run_exp.py_ √© preciso passar um arquivo de configura√ß√£o no formato _.yaml_ no formato abaixo.
 Nele est√£o as informa√ß√µes utilizadas no experimento sobre.

```yaml
"dataset":
  "name": "adult"                                                                           # nome do dataset
  "path": "datasets/adult_sklearn/adult_sklearn.csv"                                        # dataset completo
  "path_train": "datasets/adult_sklearn/adult_sklearn_train.csv"                            # dataset com split de treino
  "path_val": "datasets/adult_sklearn/adult_sklearn_val.csv"                                # dataset com split de valida√ß√£o
  "path_test": "datasets/adult_sklearn/adult_sklearn_test.csv"                              # dataset  com split  de teste   
  "cols_exclude": ["fnlwgt"]                                                                # colunas que se deseja excluir
  "cols_cat": ["workclass", "education", "marital-status", "occupation", "relationship",    
    "race", "native-country"]     # colunas categ√≥ricas para one-hot enconding
  "target": "income"       		  # atributo alvo                                        
  "sensitive": "sex"              # atributo sens√≠vel
  "privileged": ["Male"]          # valor do atributo sens√≠vel que indica o grupo privilegiado
  "unprivileged": ["Female"]      # valor do atributo sens√≠vel que indica o grupo desprivilegiado
  "favorable": ">50K"             # valor do atributo alvo que √© favor√°vel 
  "unfavorable": "<=50K"          # valor do atributo alvo que n√£o √© favor√°vel
"model":
  "name": "xgboost"                 # modelo utilizado, utilize o mesmo nome do arquivo .√Ω em \src\models    .
  "params":                         # hiper√¢metros do modelo 
    "objective": "binary:logistic"
    "n_estimators": 200
    "max_depth": 6
    "learning_rate": 0.1
    "subsample": 0.8
    "colsample_bytree": 0.8
"mitigation":
  "pre":                                      # mitiga√ß√£o pr√© utilizada, mesmo nome do .py em \src\mitigation\pre
    "name": "reweighing"
    "params": {}
  "in":                                 	  # mitiga√ß√£o in utilizada, mesmo nome do arquivo em \src\mitigation\in  
    "name": "none"                            # none indica que n√£o se quer utilizar mitiga√ß√£o naquela fase.
    "params": {}
  "post":
    "name": "equalized_odds_postprocessing"   # mitiga√ß√£o p√≥s utilizada, mesmo nome do arquivo em \src\mitigation\post
    "params": {}
```

## Gera√ß√£o de v√°rios arquivos de configura√ß√£o de experimentos

O arquivo params.yaml tem formato similar a um arquivo de configura√ß√£o de um experimento. Por√©m, ele aceita a inclus√£o de mais de modelos e mais mitigadores por fase.
Desta forma, o codigo _gera_config.py_ l√™ _params.yaml_ e realiza a combina√ß√£o dos modelos e mitigadores gerando arquivos individuais de experimentos.
Os arquivos resultantes da combina√ß√£o de modelos e mitigadores ficam armazenados em _\configs_.
Ao executar _run_all.py_ ser√£o feitas execu√ß√µes de run_exp.py para cada um dos arquivos de experimentos armazenados em _\configs_.

 
## Executar experimentos

### Executar apenas um experimento
```bash
python run_exp.py .\\configs\\adult__bernoulli_nb__pre-none__in-none__post-none.yaml
```
Se n√£o passar o arquivo _.yaml_ com os par√¢metros, ir√° buscar os par√¢metros de _config.yaml_.
A execu√ß√£o ser√° salva em _runs_adult.csv_.


### Executar v√°rios experimentos

#### Gerar os arquivos individuais de experimentos a partir dos params.yaml
```bash
python gera_configs.py
```
Os arquivos de par√¢metros _.yaml_ de cada experimento ser√£o salvos em _\configs_.

#### Executar todos os epxerimentos criados em \\configs\\

```bash
pyhton run_all.py
```
As execu√ß√µes ser√£o salvas em _runs_adult.csv_.

#### Rodar lotes de execu√ß√£o de v√°rios experimentos
```bash
lote_run_all.bat
```
As execu√ß√µes ser√£o salvas em _runs_adult.cs_v.


#### No warnings
set TF\_ENABLE\_ONEDNN\_OPTS=0

